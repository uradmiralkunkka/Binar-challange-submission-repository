{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "from flask import request\n",
    "from flasgger import Swagger, LazyString, LazyJSONEncoder\n",
    "from flasgger import swag_from\n",
    "\n",
    "\"\"\"Review: good, pembacaan file nya udah tepat, ditaruh dipal;ing atas buat mudahn trace file\"\"\"\n",
    "df = pd.read_csv('data.csv', encoding='latin-1') #data that will be analyzed\n",
    "\n",
    "alay_dictionary = pd.read_csv('new_kamusalay.csv', encoding='latin-1', header=None) #data \"alay dictionary\"\n",
    "alay_dictionary = alay_dictionary.rename(columns={0: 'original', \n",
    "                                      1: 'replacement'}) \n",
    "\n",
    "d_abusive = pd.read_csv('abusive.csv', encoding='latin-1', header=None) #data abusive.\n",
    "d_abusive = d_abusive.rename(columns={0: 'abusive'}) \n",
    "\n",
    "d_stopword1 = pd.read_csv('stopwordbahasa.csv', header=None) #data stop word.\n",
    "d_stopword1 = d_stopword1.rename(columns={0: 'stopword'})\n",
    "stopwords_new = pd.DataFrame(['sih','nya', 'iya', 'nih', 'biar', 'tau', 'kayak', 'banget'], columns=['stopword'])\n",
    "d_stopword1 = pd.concat([d_stopword1,stopwords_new]).reset_index()\n",
    "d_stopword1 = pd.DataFrame(d_stopword1['stopword'])\n",
    "\n",
    "#Tempalte swagger\n",
    "app.json_encoder = LazyJSONEncoder\n",
    "swagger_template = dict(\n",
    "info = {\n",
    "    'title': LazyString(lambda: 'API Documentation for Data Processing and Modeling'),\n",
    "    'version': LazyString(lambda: '1.0.0'),\n",
    "    'description': LazyString(lambda: 'Dokumentasi API untuk Data Processing dan Modeling'),\n",
    "    },\n",
    "    host = LazyString(lambda: request.host)\n",
    ")\n",
    "swagger_config = {\n",
    "    \"headers\": [],\n",
    "    \"specs\": [\n",
    "        {\n",
    "            \"endpoint\": 'docs',\n",
    "            \"route\": '/docs.json',\n",
    "        }\n",
    "    ],\n",
    "    \"static_url_path\": \"/flasgger_static\",\n",
    "    \"swagger_ui\": True,\n",
    "    \"specs_route\": \"/docs/\"\n",
    "}\n",
    "swagger = Swagger(app, template=swagger_template,             \n",
    "                  config=swagger_config)\n",
    "\n",
    "# end template swagger\n",
    "\n",
    "# Inisialisasi fungsi\n",
    "# rules 1\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# rules 2\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove retweet symbol\n",
    "    text = re.sub('user',' ',text) # Username omitted\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove URL\n",
    "    text = re.sub('  +', ' ', text) # Extra spaces removed\n",
    "    return text\n",
    "\n",
    "# rules 3\n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "# rules 4\n",
    "alay_dict_map = dict(zip(alay_dictionary['original'], alay_dictionary['replacement']))\n",
    "def normalize_alay(text):\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "# rules 5\n",
    "def remove_abusive(text):\n",
    "    text = ' '.join(['' if word in d_abusive.abusive.values else word for word in text.split(' ')])\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# rules 5\n",
    "def stopword_remover(text):\n",
    "    text = ' '.join(['' if word in d_stopword1.stopword.values else word for word in text.split(' ')])\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# jadikan seluruh fungsi dalam 1 fungs\n",
    "def preprocess(text):\n",
    "    text = lowercase(text) # 1 Replacing capital letters with lowercase letters\n",
    "    text = remove_nonaplhanumeric(text) # 2 Removes all characters other than alphabets\n",
    "    text = remove_unnecessary_char(text) # 3 Remove unnecessary characters\n",
    "    text = normalize_alay(text) # 4 Eliminate \"alay\" words, and replace them with standard words.\n",
    "    text = remove_abusive(text) # 5 Eliminate abusive words\n",
    "    text = stopword_remover(text) \n",
    "    return text\n",
    "# end inisialisasi fungsi\n",
    "\n",
    "#endpoint buat ngenalin aplikasi\n",
    "@swag_from(\"docs/landingpage.yml\", methods=['GET'])\n",
    "@app.route('/', methods=['GET'])\n",
    "def hello_world():\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"DISINI KASIH JUDUL APLIKASI SESUAI REPORT\",\n",
    "        'data': \"Binar Academy - Nama - DSC 7\",\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "# endpoint pertama cleansing dari form input\n",
    "@swag_from(\"docs/text_processing.yml\", methods=['POST'])\n",
    "@app.route('/text-processing', methods=['POST'])\n",
    "def text_processing():\n",
    "\n",
    "    text = request.form.get('text')\n",
    "\n",
    "    \"\"\"Review disini masukin fungsi yang udah di gabung yaitu fungsi def preprocess(text)\"\"\"\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Teks yang sudah diproses\",\n",
    "        # 'data': re.sub(r'[^a-zA-Z0-9]', ' ', text),\n",
    "        'data' : preprocess(text)\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "# endpoint kedua cleansing dari file\n",
    "@swag_from(\"docs/text_processing_file.yml\", methods=['POST'])\n",
    "@app.route('/text-processing-file', methods=['POST'])\n",
    "def text_processing_file():\n",
    "\n",
    "    # Upladed file\n",
    "    file = request.files.getlist('file')[0]\n",
    "\n",
    "    # Import file csv ke Pandas\n",
    "    df = pd.read_csv(file, encoding='latin-1')\n",
    "\n",
    "    # Ambil teks yang akan diproses dalam format list\n",
    "    # texts = df.text.to_list()\n",
    "\n",
    "    # Lakukan cleansing pada teks\n",
    "    cleaned_text = []\n",
    "    for text in df['Tweet']:\n",
    "        \"\"\"Review disini masukin fungsi yang udah di gabung yaitu fungsi def preprocess(text)\"\"\"\n",
    "        # cleaned_text.append(re.sub(r'[^a-zA-Z0-9]', ' ', text))\n",
    "        cleaned_text.append(preprocess(text))\n",
    "\n",
    "    df['cleaned_text'] = cleaned_text\n",
    "\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Teks yang sudah diproses\",\n",
    "        'data': cleaned_text\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76536811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
